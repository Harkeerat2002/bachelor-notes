- Key innovation: **Attention** that captures semantic relation between words. 
# Transformers Architecture
![[../../../Attachments/Pasted image 20231120114400.png|250]]

- **Attention**
- **Multi-Head Attention**
- **Input Embedding**
- **Positional Encoding**
- **FFNN**
- 