- ## Stacked RNNs
- ## Backpropagation through Time
	- ## Gradient Clipping
		- *Shrink the learning rate*
		- If the gradient is too large replace it with a vector having the same direction but a smaller norm
	