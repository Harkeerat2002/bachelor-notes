# Variance of Noise:
# Train vs Test Split:
# K-fold cross-validation:
# Underfitting and Overfitting:
# Why does Generalization error follow a u-curve?
## Bias of Simple Models:
## Bias of Complex Models:
## Variance of Complex Models:
## Variance in the overparameterized noiseless case:
# Regularization:
## Polynomial Regression:
## Controlling Model Complexity via Degree:
## Controlling Model Complexity via Sparsity:
## Model Comlexity Reflected in Norms:
## Controlling model complexity via $l_2$ norm:
## Effect of Ridge Regression on Estimator Norm
## Ridge regression on Polynomial Features
## Comparing Lasso and Ridge Regression
## Why $l_1$-penalty induces sparsity - via norm definitions
## Why $l_1$-penalty induces sparsity - via geometry
## How to implement the design choices so far?
## Cross-validation to determine regularization strength:
## Model Selection for regularized models


